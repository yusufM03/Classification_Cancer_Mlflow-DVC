{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\youss\\\\OneDrive\\\\Bureau\\\\computer vision\\\\Projet_sign recognitin\\\\keypointsapproach\\\\classification'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "    classes:int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification.constants import *\n",
    "from classification.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        \n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir,\"Data\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            classes=params.CLASSES\n",
    "        )\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from classification import logger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "#Component \n",
    "class training_Model:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "\n",
    "    def Processing_Data(self):\n",
    "        Train_Data=os.path.join(self.config.training_data,'Train')\n",
    "        X_train=[]\n",
    "        y_train=[]\n",
    "        for classe in os.listdir(Train_Data):\n",
    "              \n",
    "          for img in os.listdir(os.path.join(Train_Data,classe)) :\n",
    "            img_path=os.path.join(Train_Data,classe,img)\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(75,75))\n",
    "            x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "            x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "            X_train.append(x)\n",
    "            y_train.append(classe)\n",
    "        \n",
    "\n",
    "      \n",
    "  \n",
    "        val_Data=os.path.join(self.config.training_data,'valid')\n",
    "        X_val=[]\n",
    "        y_val=[]\n",
    "\n",
    "        for classe in os.listdir(val_Data):\n",
    "            \n",
    "          for img in os.listdir(os.path.join(val_Data,classe)) :\n",
    "            img_path=os.path.join(val_Data,classe,img)\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(75,75))\n",
    "            x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "            x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "            X_val.append(x)\n",
    "            y_val.append(classe)\n",
    "\n",
    "\n",
    "                # Convert y_train to a NumPy array\n",
    "        y_train_array = np.array(y_train)\n",
    "        y_val_array = np.array(y_val)\n",
    "\n",
    "        # Reshape y_train for one-hot encoding\n",
    "        y_train_reshaped = y_train_array.reshape(-1, 1)\n",
    "        y_val_reshaped = y_val_array.reshape(-1, 1)\n",
    "\n",
    "        # Initialize the one-hot encoder\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "      \n",
    "        # Fit one-hot encoder and transform y_train\n",
    "        y_train_onehot = onehot_encoder.fit_transform(y_train_reshaped)\n",
    "        y_val_onehot = onehot_encoder.transform(y_val_reshaped)\n",
    "\n",
    "        self.hotencoder=  onehot_encoder\n",
    "\n",
    "\n",
    "        \n",
    "        X_train=np.array(X_train)\n",
    "        X_val=np.array(X_val)\n",
    "        self.X_train=X_train\n",
    "        self.y_train=  y_train_onehot\n",
    "        self.X_val=X_val\n",
    "        self.y_val=   y_val_onehot\n",
    "      \n",
    "        \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "        self.model.fit(\n",
    "            self.X_train,self.y_train,\n",
    "            epochs=self.config.params_epochs,\n",
    "            validation_data=(self.X_val,self.y_val),\n",
    "            batch_size=self.config.params_batch_size,callbacks=[early_stopping_callback]\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate):\n",
    "        if freeze_all:\n",
    "            for layer in model.layers:\n",
    "                model.trainable = False\n",
    "        elif (freeze_till is not None) and (freeze_till > 0):\n",
    "            for layer in model.layers[:-freeze_till]:\n",
    "                model.trainable = False\n",
    "\n",
    "        full_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(75, 75, 3), padding = \"same\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(4, activation='softmax')\n",
    "        ])\n",
    "                    \n",
    "        # Define optimizer with learning rate decay\n",
    "        batches_per_epoch = len(self.X_train)*self.config.params_batch_size\n",
    "        lr_decay = (1./0.75 - 1) / batches_per_epoch\n",
    "        opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=lr_decay)\n",
    "        \n",
    "        # Compile the model with Adam optimizer\n",
    "        full_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "        full_model.summary()\n",
    "        return full_model\n",
    "    \n",
    "\n",
    "    def update_base_model(self):\n",
    "        self.full_model = self._prepare_full_model(\n",
    "            model=self.model,\n",
    "            classes=self.config.params_classes,\n",
    "            freeze_all=True,\n",
    "            freeze_till=None,\n",
    "            learning_rate=self.config.params_learning_rate\n",
    "        )\n",
    "\n",
    "        self.save_model(path=self.config.updated_base_model_path, model=self.full_model)\n",
    "    \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-27 02:58:13,561: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-27 02:58:13,565: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-27 02:58:13,567: INFO: common: created directory at: artifacts]\n",
      "[2024-03-27 02:58:13,567: INFO: common: created directory at: artifacts\\training]\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 75, 75, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     Training_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     Training_model\u001b[38;5;241m.\u001b[39mget_base_model()\n\u001b[0;32m      7\u001b[0m     Training_model\u001b[38;5;241m.\u001b[39mProcessing_Data()\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mTraining_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[11], line 97\u001b[0m, in \u001b[0;36mtraining_Model.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     95\u001b[0m     early_stopping_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(\n\u001b[0;32m    105\u001b[0m         path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrained_model_path,\n\u001b[0;32m    106\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    107\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqzii3iu5.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    Training_model_config = config.get_training_config()\n",
    "    Training_model = training_Model(config=Training_model_config)\n",
    "    Training_model.get_base_model()\n",
    "    \n",
    "    Training_model.Processing_Data()\n",
    "    Training_model.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Processing_Data():\n",
    "        Train_Data=os.path.join(\"artifacts/data_ingestion/Data\",'Train')\n",
    "        X_train=[]\n",
    "        y_train=[]\n",
    "        for classe in os.listdir(Train_Data):\n",
    "              \n",
    "          for img in os.listdir(os.path.join(Train_Data,classe)) :\n",
    "            img_path=os.path.join(Train_Data,classe,img)\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(75,75)) \n",
    "            x = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "\n",
    "            #x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "            X_train.append(x)\n",
    "            y_train.append(classe)\n",
    "        \n",
    "\n",
    "      \n",
    "  \n",
    "        val_Data=os.path.join(\"artifacts/data_ingestion/Data\",'valid')\n",
    "        X_val=[]\n",
    "        y_val=[]\n",
    "\n",
    "        for classe in os.listdir(val_Data):\n",
    "            \n",
    "          for img in os.listdir(os.path.join(val_Data,classe)) :\n",
    "            img_path=os.path.join(val_Data,classe,img)\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(75,75)) \n",
    "            x = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "\n",
    "            #x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "            X_val.append(x)\n",
    "            y_val.append(classe)\n",
    "\n",
    "\n",
    "                # Convert y_train to a NumPy array\n",
    "        y_train_array = np.array(y_train)\n",
    "        y_val_array = np.array(y_val)\n",
    "\n",
    "        # Reshape y_train for one-hot encoding\n",
    "        y_train_reshaped = y_train_array.reshape(-1, 1)\n",
    "        y_val_reshaped = y_val_array.reshape(-1, 1)\n",
    "\n",
    "        # Initialize the one-hot encoder\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "      \n",
    "        # Fit one-hot encoder and transform y_train\n",
    "        y_train_onehot = onehot_encoder.fit_transform(y_train_reshaped)\n",
    "        y_val_onehot = onehot_encoder.transform(y_val_reshaped)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        X_train=np.array(X_train)\n",
    "        X_val=np.array(X_val)\n",
    "        \n",
    "        y_train=  y_train_onehot\n",
    "      \n",
    "        y_val=   y_val_onehot\n",
    "        return X_train,y_train,X_val,y_val\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    def train(model, X_train,y_train,X_val,y_val):\n",
    "        \n",
    "\n",
    "        model.fit(\n",
    "            X_train,y_train,\n",
    "            epochs=100,\n",
    "            validation_data=(X_val,y_val),\n",
    "            batch_size=24\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _prepare_full_model(X_train):\n",
    "    \n",
    "\n",
    "        full_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(75, 75, 3), padding = \"same\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(4, activation='softmax')\n",
    "        ])\n",
    "                    \n",
    "        # Define optimizer with learning rate decay\n",
    "        batches_per_epoch = len(X_train)*24\n",
    "        lr_decay = (1./0.75 - 1) / batches_per_epoch\n",
    "        opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=lr_decay)\n",
    "        \n",
    "        # Compile the model with Adam optimizer\n",
    "        full_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "        full_model.summary()\n",
    "        return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\anaconda3\\envs\\classification_cancer\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    " X_train,y_train,X_val,y_val=Processing_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 75, 75, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 37, 37, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 35, 35, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 17, 17, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 15, 15, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 64)                401472    \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 497,396\n",
      "Trainable params: 497,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=_prepare_full_model(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 4s 105ms/step - loss: 1.3835 - accuracy: 0.2741 - val_loss: 1.3818 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 1.3661 - accuracy: 0.3491 - val_loss: 1.3757 - val_accuracy: 0.1806\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 1.3292 - accuracy: 0.3442 - val_loss: 1.3551 - val_accuracy: 0.3889\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 1.3079 - accuracy: 0.3736 - val_loss: 1.3150 - val_accuracy: 0.4028\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 1.2508 - accuracy: 0.4307 - val_loss: 1.2597 - val_accuracy: 0.4583\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 1.2366 - accuracy: 0.4372 - val_loss: 1.2139 - val_accuracy: 0.4583\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 1.1772 - accuracy: 0.4731 - val_loss: 1.1745 - val_accuracy: 0.4722\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 1.1486 - accuracy: 0.4486 - val_loss: 1.1191 - val_accuracy: 0.4861\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 1.0908 - accuracy: 0.5090 - val_loss: 1.1032 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 1.0883 - accuracy: 0.4927 - val_loss: 1.0670 - val_accuracy: 0.5139\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 1.0327 - accuracy: 0.5090 - val_loss: 1.0478 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 1.0072 - accuracy: 0.5090 - val_loss: 1.0571 - val_accuracy: 0.4722\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.9975 - accuracy: 0.5171 - val_loss: 0.9975 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.9846 - accuracy: 0.5122 - val_loss: 1.0048 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.9651 - accuracy: 0.5302 - val_loss: 1.0050 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.9221 - accuracy: 0.5432 - val_loss: 0.9634 - val_accuracy: 0.4861\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.8858 - accuracy: 0.5938 - val_loss: 0.9470 - val_accuracy: 0.5278\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.8670 - accuracy: 0.5889 - val_loss: 0.9192 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.8387 - accuracy: 0.6020 - val_loss: 0.9222 - val_accuracy: 0.5139\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.8425 - accuracy: 0.6476 - val_loss: 0.9149 - val_accuracy: 0.5139\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.8009 - accuracy: 0.6607 - val_loss: 0.9592 - val_accuracy: 0.5417\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.7602 - accuracy: 0.6721 - val_loss: 0.8681 - val_accuracy: 0.5556\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.7925 - accuracy: 0.6493 - val_loss: 0.8359 - val_accuracy: 0.5972\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.7164 - accuracy: 0.6949 - val_loss: 0.8470 - val_accuracy: 0.5556\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.7535 - accuracy: 0.6476 - val_loss: 0.8348 - val_accuracy: 0.5556\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.7225 - accuracy: 0.6900 - val_loss: 0.8251 - val_accuracy: 0.5972\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.6684 - accuracy: 0.7374 - val_loss: 0.8605 - val_accuracy: 0.5833\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6588 - accuracy: 0.7162 - val_loss: 0.7881 - val_accuracy: 0.5694\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6511 - accuracy: 0.7325 - val_loss: 0.8084 - val_accuracy: 0.5972\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6158 - accuracy: 0.7553 - val_loss: 0.7937 - val_accuracy: 0.6111\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6056 - accuracy: 0.7390 - val_loss: 0.8025 - val_accuracy: 0.6111\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.5936 - accuracy: 0.7553 - val_loss: 0.7431 - val_accuracy: 0.6528\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.5723 - accuracy: 0.7520 - val_loss: 0.8159 - val_accuracy: 0.6528\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.5623 - accuracy: 0.7732 - val_loss: 0.7430 - val_accuracy: 0.6528\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.5327 - accuracy: 0.7928 - val_loss: 0.7125 - val_accuracy: 0.7083\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.5451 - accuracy: 0.7896 - val_loss: 0.7880 - val_accuracy: 0.6528\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.5116 - accuracy: 0.8108 - val_loss: 0.6744 - val_accuracy: 0.7222\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.4967 - accuracy: 0.8075 - val_loss: 0.6574 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.4509 - accuracy: 0.8140 - val_loss: 0.7051 - val_accuracy: 0.7083\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.4776 - accuracy: 0.8059 - val_loss: 0.7392 - val_accuracy: 0.7083\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.4745 - accuracy: 0.8140 - val_loss: 0.7818 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.4545 - accuracy: 0.8206 - val_loss: 0.6338 - val_accuracy: 0.7222\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.4391 - accuracy: 0.8157 - val_loss: 0.6828 - val_accuracy: 0.7222\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.4269 - accuracy: 0.8320 - val_loss: 0.6284 - val_accuracy: 0.7361\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.4204 - accuracy: 0.8385 - val_loss: 0.6443 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.3719 - accuracy: 0.8597 - val_loss: 0.6208 - val_accuracy: 0.7361\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.3908 - accuracy: 0.8467 - val_loss: 0.6020 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.3747 - accuracy: 0.8564 - val_loss: 0.6738 - val_accuracy: 0.7222\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.3751 - accuracy: 0.8434 - val_loss: 0.6141 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.3481 - accuracy: 0.8597 - val_loss: 0.5993 - val_accuracy: 0.7917\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.3705 - accuracy: 0.8630 - val_loss: 0.6004 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.3414 - accuracy: 0.8630 - val_loss: 0.6546 - val_accuracy: 0.7361\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.3278 - accuracy: 0.8728 - val_loss: 0.6708 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.3679 - accuracy: 0.8434 - val_loss: 0.5923 - val_accuracy: 0.7639\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.3386 - accuracy: 0.8695 - val_loss: 0.6208 - val_accuracy: 0.7639\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.3121 - accuracy: 0.8695 - val_loss: 0.6146 - val_accuracy: 0.7639\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.2981 - accuracy: 0.8874 - val_loss: 0.6116 - val_accuracy: 0.7361\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.3183 - accuracy: 0.8777 - val_loss: 0.5958 - val_accuracy: 0.7639\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.2909 - accuracy: 0.9005 - val_loss: 0.6948 - val_accuracy: 0.7639\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.3012 - accuracy: 0.8695 - val_loss: 0.6337 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.2723 - accuracy: 0.8940 - val_loss: 0.6826 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.2627 - accuracy: 0.8972 - val_loss: 0.6880 - val_accuracy: 0.7083\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.2642 - accuracy: 0.9005 - val_loss: 0.5698 - val_accuracy: 0.7639\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.2390 - accuracy: 0.9119 - val_loss: 0.6147 - val_accuracy: 0.7639\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.2376 - accuracy: 0.9233 - val_loss: 0.5850 - val_accuracy: 0.7639\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.2606 - accuracy: 0.9054 - val_loss: 0.6063 - val_accuracy: 0.7639\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.2280 - accuracy: 0.9184 - val_loss: 0.6372 - val_accuracy: 0.7639\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.2318 - accuracy: 0.9135 - val_loss: 0.5996 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.2300 - accuracy: 0.9217 - val_loss: 0.5244 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.2349 - accuracy: 0.9135 - val_loss: 0.5514 - val_accuracy: 0.7639\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.2053 - accuracy: 0.9315 - val_loss: 0.5945 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.2074 - accuracy: 0.9217 - val_loss: 0.6577 - val_accuracy: 0.7361\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.2235 - accuracy: 0.9168 - val_loss: 0.5720 - val_accuracy: 0.7778\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.1898 - accuracy: 0.9266 - val_loss: 0.5908 - val_accuracy: 0.7778\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.1874 - accuracy: 0.9347 - val_loss: 0.5811 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.1804 - accuracy: 0.9347 - val_loss: 0.5660 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.1818 - accuracy: 0.9364 - val_loss: 0.5959 - val_accuracy: 0.7639\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.2004 - accuracy: 0.9331 - val_loss: 0.5821 - val_accuracy: 0.7639\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.1818 - accuracy: 0.9282 - val_loss: 0.6299 - val_accuracy: 0.7778\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.1747 - accuracy: 0.9380 - val_loss: 0.5874 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.1815 - accuracy: 0.9380 - val_loss: 0.6388 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.1642 - accuracy: 0.9380 - val_loss: 0.5875 - val_accuracy: 0.7778\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.1981 - accuracy: 0.9299 - val_loss: 0.5420 - val_accuracy: 0.8056\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.1688 - accuracy: 0.9347 - val_loss: 0.5688 - val_accuracy: 0.7778\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.1526 - accuracy: 0.9494 - val_loss: 0.6271 - val_accuracy: 0.7639\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.1579 - accuracy: 0.9364 - val_loss: 0.5218 - val_accuracy: 0.8056\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.1297 - accuracy: 0.9625 - val_loss: 0.6092 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.1420 - accuracy: 0.9462 - val_loss: 0.6185 - val_accuracy: 0.7917\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 3s 96ms/step - loss: 0.1357 - accuracy: 0.9543 - val_loss: 0.5785 - val_accuracy: 0.8194\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.1350 - accuracy: 0.9445 - val_loss: 0.5180 - val_accuracy: 0.8056\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.1413 - accuracy: 0.9445 - val_loss: 0.5757 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.1202 - accuracy: 0.9560 - val_loss: 0.5842 - val_accuracy: 0.7778\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.1500 - accuracy: 0.9429 - val_loss: 0.6294 - val_accuracy: 0.7917\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.1508 - accuracy: 0.9396 - val_loss: 0.5866 - val_accuracy: 0.7778\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.1223 - accuracy: 0.9560 - val_loss: 0.5527 - val_accuracy: 0.7917\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.1132 - accuracy: 0.9641 - val_loss: 0.6330 - val_accuracy: 0.7639\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.1097 - accuracy: 0.9543 - val_loss: 0.6556 - val_accuracy: 0.7778\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.1251 - accuracy: 0.9527 - val_loss: 0.6155 - val_accuracy: 0.8056\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 2s 97ms/step - loss: 0.1192 - accuracy: 0.9625 - val_loss: 0.8172 - val_accuracy: 0.7778\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.1173 - accuracy: 0.9608 - val_loss: 0.7632 - val_accuracy: 0.7917\n"
     ]
    }
   ],
   "source": [
    "train(model,X_train,y_train,X_val,y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
